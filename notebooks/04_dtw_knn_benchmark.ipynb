{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9fdebdd3-17fb-4dc6-b583-d523984d4bbe",
   "metadata": {},
   "source": [
    "# Notebook 4: DTW + KNN Benchmark on Standardized Data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b720078-5543-4360-98a4-d0cf0d57cf2a",
   "metadata": {},
   "source": [
    "## Setup & Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7d375768-a9a5-4e37-a9a5-2f15182ce251",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy.spatial.distance import euclidean\n",
    "from fastdtw import fastdtw\n",
    "from tqdm import tqdm\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import time\n",
    "import pickle\n",
    "import os\n",
    "\n",
    "# Set random seed for reproducibility\n",
    "np.random.seed(42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2ea1639-0c25-4dda-9fb1-6510bacbe07d",
   "metadata": {},
   "source": [
    "## Load 10D Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "59a84efb-4f46-43ee-a278-9afe2c1a8ee9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Dataset loaded successfully!\n",
      "   Total samples: 1299\n",
      "   Sequence length: 31 timepoints\n",
      "   Number of sensors: 10 (10D)\n",
      "   Unique labels: [0 1 2 3 4 5 6 7 8]\n"
     ]
    }
   ],
   "source": [
    "def load_standardized_10d_data(data_path=r\"C:\\Users\\jumia\\Downloads\\BackTap\\backtapbench_standard\\backtapbench_data.npz\"):\n",
    "    \"\"\"\n",
    "    Load the standardized 10D dataset from the .npz file created in Notebook 3.\n",
    "    \"\"\"\n",
    "    if not os.path.exists(data_path):\n",
    "        raise FileNotFoundError(f\"Dataset not found at {data_path}. Please run Notebooks 1-3 first.\")\n",
    "    \n",
    "    # Load the compressed numpy file\n",
    "    data = np.load(data_path)\n",
    "    \n",
    "    # Extract data\n",
    "    X = data['segments']      # Shape: (n_samples, 31, 10)\n",
    "    y = data['labels']        # Shape: (n_samples,)\n",
    "    \n",
    "    print(f\"âœ… Dataset loaded successfully!\")\n",
    "    print(f\"   Total samples: {X.shape[0]}\")\n",
    "    print(f\"   Sequence length: {X.shape[1]} timepoints\")\n",
    "    print(f\"   Number of sensors: {X.shape[2]} (10D)\")\n",
    "    print(f\"   Unique labels: {np.unique(y)}\")\n",
    "    \n",
    "    return X, y\n",
    "\n",
    "# Load the full dataset\n",
    "X, y = load_standardized_10d_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "907f9bf1-9240-4bc7-b959-525e72845e50",
   "metadata": {},
   "source": [
    "## Train/Test Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "75f3c3d7-1936-4eba-b9c6-ed98d5b70f1c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ðŸ“Š Data split:\n",
      "   Training: 1039 samples\n",
      "   Test: 260 samples\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Use the same split as in Notebook 3 for consistency\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42, stratify=y\n",
    ")\n",
    "\n",
    "print(f\"\\nðŸ“Š Data split:\")\n",
    "print(f\"   Training: {X_train.shape[0]} samples\")\n",
    "print(f\"   Test: {X_test.shape[0]} samples\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e74f33a-00c5-438d-bc36-ec6c6a1e058c",
   "metadata": {},
   "source": [
    "## DTW Computation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "8593db87-0191-4c7b-bd8d-433e61c3b690",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_dtw_distance_matrix(X1, X2, batch_size=100):\n",
    "    \"\"\"\n",
    "    Compute DTW distance matrix with batch processing for memory efficiency.\n",
    "    \"\"\"\n",
    "    n1, n2 = len(X1), len(X2)\n",
    "    distance_matrix = np.zeros((n1, n2))\n",
    "    \n",
    "    total_comparisons = n1 * n2\n",
    "    print(f\"Computing {total_comparisons:,} DTW distances...\")\n",
    "    \n",
    "    for i in tqdm(range(n1), desc=\"Processing sequences\"):\n",
    "        for j in range(n2):\n",
    "            # DTW with Euclidean distance\n",
    "            dist, _ = fastdtw(X1[i], X2[j], dist=euclidean)\n",
    "            distance_matrix[i, j] = dist\n",
    "    \n",
    "    return distance_matrix\n",
    "\n",
    "def get_cached_distance_matrices(X_train, X_test, cache_dir='dtw_cache'):\n",
    "    \"\"\"\n",
    "    Load cached distance matrices or compute and cache them.\n",
    "    \"\"\"\n",
    "    os.makedirs(cache_dir, exist_ok=True)\n",
    "    \n",
    "    train_cache = os.path.join(cache_dir, 'dtw_train_distance.npy')\n",
    "    test_cache = os.path.join(cache_dir, 'dtw_test_distance.npy')\n",
    "    \n",
    "    if os.path.exists(train_cache) and os.path.exists(test_cache):\n",
    "        print(\"ðŸ“¦ Loading cached distance matrices...\")\n",
    "        distance_train = np.load(train_cache)\n",
    "        distance_test = np.load(test_cache)\n",
    "        print(f\"   Train distance matrix: {distance_train.shape}\")\n",
    "        print(f\"   Test distance matrix: {distance_test.shape}\")\n",
    "    else:\n",
    "        print(\"ðŸ”„ Computing DTW distance matrices (this may take a while)...\")\n",
    "        start_time = time.time()\n",
    "        \n",
    "        distance_train = compute_dtw_distance_matrix(X_train, X_train)\n",
    "        distance_test = compute_dtw_distance_matrix(X_test, X_train)\n",
    "        \n",
    "        compute_time = time.time() - start_time\n",
    "        print(f\"   Computation time: {compute_time:.2f} seconds\")\n",
    "        \n",
    "        # Cache for future use\n",
    "        np.save(train_cache, distance_train)\n",
    "        np.save(test_cache, distance_test)\n",
    "        print(f\"   ðŸ’¾ Cached to {cache_dir}/\")\n",
    "    \n",
    "    return distance_train, distance_test"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d11d34b9-f3ce-4d9f-823c-52fadab79dc2",
   "metadata": {},
   "source": [
    "## DTW + KNN Benchmark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "88ce4be6-9d2b-4be6-a852-713890af7fe7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_dtw_knn_benchmark(X_train, X_test, y_train, y_test, use_cache=True, k=1):\n",
    "    \"\"\"\n",
    "    Complete DTW + KNN benchmark pipeline.\n",
    "    \"\"\"\n",
    "    start_time = time.time()\n",
    "    \n",
    "    print(\"\\n\" + \"=\"*70)\n",
    "    print(\"ðŸš€ DTW + KNN BENCHMARK (10D Standardized Data)\")\n",
    "    print(\"=\"*70)\n",
    "    \n",
    "    # 1. Encode labels\n",
    "    le = LabelEncoder()\n",
    "    y_train_enc = le.fit_transform(y_train)\n",
    "    y_test_enc = le.transform(y_test)\n",
    "    \n",
    "    # 2. Compute/load distance matrices\n",
    "    if use_cache:\n",
    "        distance_train, distance_test = get_cached_distance_matrices(X_train, X_test)\n",
    "    else:\n",
    "        distance_train = compute_dtw_distance_matrix(X_train, X_train)\n",
    "        distance_test = compute_dtw_distance_matrix(X_test, X_train)\n",
    "    \n",
    "    # 3. Train KNN with precomputed metric\n",
    "    print(\"\\nðŸ¤– Training KNN classifier...\")\n",
    "    knn = KNeighborsClassifier(n_neighbors=k, metric='precomputed')\n",
    "    knn.fit(distance_train, y_train_enc)\n",
    "    \n",
    "    # 4. Predict\n",
    "    print(\"   Making predictions...\")\n",
    "    y_pred = knn.predict(distance_test)\n",
    "    \n",
    "    # 5. Evaluate\n",
    "    accuracy = accuracy_score(y_test_enc, y_pred)\n",
    "    exec_time = time.time() - start_time\n",
    "    \n",
    "    print(f\"\\nâœ… Results:\")\n",
    "    print(f\"   Accuracy: {accuracy*100:.2f}%\")\n",
    "    print(f\"   Execution time: {exec_time:.2f} seconds\")\n",
    "    print(f\"   k = {k}\")\n",
    "    \n",
    "    return {\n",
    "        'accuracy': accuracy,\n",
    "        'y_pred': y_pred,\n",
    "        'y_test_enc': y_test_enc,\n",
    "        'execution_time': exec_time,\n",
    "        'knn_model': knn,\n",
    "        'label_encoder': le,\n",
    "        'distance_test': distance_test\n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c56dfaba-af80-4611-a33b-2a103f2c83e5",
   "metadata": {},
   "source": [
    "## Execute Benchmark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "72cae38b-0655-466f-8768-e26655f288fc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======================================================================\n",
      "ðŸš€ DTW + KNN BENCHMARK (10D Standardized Data)\n",
      "======================================================================\n",
      "ðŸ”„ Computing DTW distance matrices (this may take a while)...\n",
      "Computing 1,079,521 DTW distances...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing sequences: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1039/1039 [3:56:29<00:00, 13.66s/it]   \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing 270,140 DTW distances...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing sequences: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 260/260 [26:51<00:00,  6.20s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Computation time: 15801.07 seconds\n",
      "   ðŸ’¾ Cached to dtw_cache/\n",
      "\n",
      "ðŸ¤– Training KNN classifier...\n",
      "   Making predictions...\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'accuracy_score' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[24], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# Run the benchmark\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m results \u001b[38;5;241m=\u001b[39m run_dtw_knn_benchmark(\n\u001b[0;32m      3\u001b[0m     X_train, X_test, y_train, y_test, \n\u001b[0;32m      4\u001b[0m     use_cache\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, k\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m\n\u001b[0;32m      5\u001b[0m )\n",
      "Cell \u001b[1;32mIn[21], line 33\u001b[0m, in \u001b[0;36mrun_dtw_knn_benchmark\u001b[1;34m(X_train, X_test, y_train, y_test, use_cache, k)\u001b[0m\n\u001b[0;32m     30\u001b[0m y_pred \u001b[38;5;241m=\u001b[39m knn\u001b[38;5;241m.\u001b[39mpredict(distance_test)\n\u001b[0;32m     32\u001b[0m \u001b[38;5;66;03m# 5. Evaluate\u001b[39;00m\n\u001b[1;32m---> 33\u001b[0m accuracy \u001b[38;5;241m=\u001b[39m accuracy_score(y_test_enc, y_pred)\n\u001b[0;32m     34\u001b[0m exec_time \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime() \u001b[38;5;241m-\u001b[39m start_time\n\u001b[0;32m     36\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124mâœ… Results:\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'accuracy_score' is not defined"
     ]
    }
   ],
   "source": [
    "# Run the benchmark\n",
    "results = run_dtw_knn_benchmark(\n",
    "    X_train, X_test, y_train, y_test, \n",
    "    use_cache=True, k=1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dafcaa27-955b-4970-bc46-1d4a5bc1bfbf",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
